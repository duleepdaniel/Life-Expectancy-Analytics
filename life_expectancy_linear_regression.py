# -*- coding: utf-8 -*-
"""Life Expectancy Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BByIK4EGXH2J7hVrHIONpqtxJpxbu1do

<center> <h1>Linear Regression Model To Predict Life Expectancy of Indiviuals from Different Countries</h1> </center>

<center> <h3>A. Problem Description</h3> </center>

<h3>Model Description:</h3>
<ul>
    <li>The model used in this analysis is a linear regression model, aiming to establish a linear relationship between the dependent variable, "Life expectancy," and 17 independent variables.</li>
    <li>The 17 independent variables are: "Country," "Year," "Status," "Population," "Hepatitis B," "Measles," "Polio," "Diphtheria," "HIV/AIDS," "Infant deaths," "Under-five deaths," "Total expenditure," "GDP," "BMI," "Thinness (1-19 years)," "Alcohol," and "Schooling."</li>
    <li>The model estimates coefficients for each input feature, representing the strength and direction of their influence on the target variable, "Life expectancy."</li>
</ul>

<h3>Our project aims to:</h3>
<ul>
    <ul>
    <li>Perform a comprehensive analysis of the "Life Expectancy" attribute, which serves as the target feature.</li>
    <li>Utilize the remaining fields in the dataset as input features for conducting extensive linear regression testing.</li>
    <li>Explore the intricate relationships and correlations between the input features and the target feature (life expectancy).</li>
    <li>Identify and determine the significant factors that wield substantial influence on the captivating realm of life expectancy.</li>
</ul>
</ul>

<center><h3>B. Data Summary</h3></center>
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import train_test_split , GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor

# Reading the Data and storing it as a Data Frame
df = pd.read_csv('./life_expectancy.csv')
df.head(10)

# Reading the info of the Dataset
df.info()

df.describe()

df.describe(include = "object")

# Checking for any Duplicates
print("Number of duplicate data : ",df.duplicated().sum())

# Counting the Number of Null Values
df.isna().sum()

"""<h5>
    As there are Null Values within the dataset, we need to do some data preprocessing to handle them.
    We decided to go with Imputation Approach - We will be calculating the mean and median value across and replace the Null Values.
</h5>

Reference Articles: https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779

<h5>Some other things we are doing with the dataset:</h5>
    <ul>
        <li>Replacing the categorical field values of 'Status' to 0,1. Developing: 0 and Developed: 1</li>
        <li>Dropping the field 'Country'</li>
    </ul>

<h4>

</h4>
"""

class Preprocessing():
    def __init__(self):
        self.col_means = {}
        self.col_medians = {}

    def fit(self, data):
        cols_with_na = data.isna().sum()[data.isna().sum()>0].index.tolist()
        for col in cols_with_na:
            self.col_means[col] = data.groupby('Country')[col].transform('mean')
            self.col_medians[col] = data[col].median()

    def transform(self, data):
        cols_with_na = data.isna().sum()[data.isna().sum()>0].index.tolist()
        # Calculating Mean
        for col in cols_with_na:
            mean_value = self.col_means[col]
            data.loc[:, col].fillna(mean_value, inplace=True)

        cols_with_na = data.isna().sum()[data.isna().sum()>0].index.tolist()
        # Calculating Mean
        for col in cols_with_na:
            median_value = self.col_medians[col]
            data.loc[:, col].fillna(median_value, inplace=True)

        # Replacing the status column to 0,1 as this is a categorial field
        data['Status'].replace({'Developing' : 0, 'Developed' : 1,}, inplace=True)

        # Drop 'Country' column as it contains non-numeric values
        data.drop(columns=['Country'], inplace=True)

        return data


    def fit_transform(self, data):
        self.fit(data)
        return self.transform(data)

preprocesser = Preprocessing()
modified_df = preprocesser.fit_transform(df)

modified_df.head(15)

modified_df.isna().sum()

# Histogram of the Target Feature - Life Expectancy
fig_hist = px.histogram(modified_df, x="Life expectancy", title="Histogram of Life expectancy")
fig_hist.update_layout(yaxis_title="Count", bargap=0.08)
fig_hist.show()

# Correlation Heatmap of All Features of Dataset
df_corr = modified_df.corr(numeric_only=True)

fig = px.imshow(df_corr,
                labels=dict(x="Features", y="Features"),
                x=df_corr.columns,
                y=df_corr.columns,
                color_continuous_scale="Blues",
                color_continuous_midpoint=0)

fig.update_layout(
    title="Correlation Heatmap",
    width=800,
    height=500,
    xaxis_showgrid=False,
    yaxis_showgrid=False,
    yaxis_autorange='reversed')

fig.show()

# Check summary statistics
modified_df.describe().style.background_gradient(cmap='Blues')

"""<center>
    <h3>C. Data Splitting</h3>
</center>

<h4>Dividing the dataset into training and testing sets with 80% and 20%</h4>
"""

# Initalizing Dataframes
X = modified_df.drop(columns=['Life expectancy'])
y = modified_df['Life expectancy']

# Splitting the Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

"""<center>
    <h3>D. Data Visualization</h3>
</center>
"""

class SampleVisualization:
    def __init__(self, input_data):
        self.data = input_data.copy()

class ChildSampleVisualization(SampleVisualization):
    def __init__(self, input_data):
        super().__init__(input_data)

    def visualize_scatter(self, target, input_features, plot_n_rows, plot_n_columns):
        # Create subplots for scatter plots
        fig, axs = plt.subplots(nrows=plot_n_rows, ncols=plot_n_columns, figsize=(20, 60))

        # Adjust the spacing between subplots
        plt.subplots_adjust(wspace=0.5, hspace=0.5)

        axs_flat = axs.ravel()  # Flatten the array
        # Iterate through input_features and plot each feature against the target
        for i, column in enumerate(input_features):
            ax = axs_flat[i]  # Access the subplots using flattened indexing
            ax.scatter(self.data[column], self.data[target])
            ax.set_title(column)
            ax.set_xlabel(column)
            ax.set_ylabel(target)
        # Display the scatter plots
        plt.show()

    def visualize_boxplot(self, target, input_features, plot_n_rows, plot_n_columns):
        # Create subplots for box plots
        fig, axs = plt.subplots(nrows=plot_n_rows, ncols=plot_n_columns, figsize=(10, 5))

        # Adjust the spacing between subplots
        plt.subplots_adjust(wspace=2, hspace=1)

        axs_flat = axs.ravel()
        # Iterate through input_features and plot each feature against the target
        for i, column in enumerate(input_features):
            ax = axs_flat[i]
            self.data.boxplot(column=target, by=column, ax=ax)
            ax.set_title(f"{target} vs. {column}")
            ax.set_xlabel(column)
            ax.set_ylabel(target)
            ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
        # Display the box plots
        plt.show()

# Train DataSet
train_df = pd.concat([X_train, y_train], axis=1)

visualization_object = ChildSampleVisualization(train_df)

# Defining the Features
target_feature = 'Life expectancy'
scatter_plot_features = [
    'Population', 'Hepatitis B', 'Measles', 'Polio', 'Diphtheria', 'HIV/AIDS', 'infant deaths',
    'under-five deaths', 'Total expenditure', 'GDP', 'BMI', 'thinness  1-19 years', 'Alcohol',
    'Schooling'
]
boxplot_features = ["Year", "Status"]

# Scatter plot
scatterplot_rows = 7
scatterplot_columns = 2

visualization_object.visualize_scatter(target=target_feature, input_features=scatter_plot_features,
                                       plot_n_rows=scatterplot_rows, plot_n_columns=scatterplot_columns)

#Box Plot
boxplot_rows = 1
boxplot_columns = 2
# Plot box plots of the input features against the target feature
visualization_object.visualize_boxplot(target=target_feature, input_features=boxplot_features,
                                       plot_n_rows=boxplot_rows, plot_n_columns=boxplot_columns)

# Histogram of the Features
total_features = scatter_plot_features + boxplot_features

plt.figure(figsize=(10, 8))
for column in total_features:
    plt.hist(train_df[column], bins=20, alpha=0.6, label=column)

plt.xlabel('Value')
plt.ylabel('Frequency')
plt.title('Histograms of Numerical Features')
plt.legend()
plt.show()

"""<center>
    <h3>E. Feature selection</h3>
    <h4>Using the SelectKBest with f_regression to select the top 5 features</h4>
</center>
"""

# f_regression to select the Top 5 Features
selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X_train, y_train)

# Get the selected feature names
selected_feature_names = X.columns[selector.get_support()].tolist()

print("Selected Features:", selected_feature_names)
# selected_feature_names = ['thinness  1-19 years', 'under-five deaths', 'HIV/AIDS', 'BMI', 'Schooling']

# Creating the DataSets with the selected features. We will be using this new Datasets to Train the Model
X_train_selected = X_train[selected_feature_names]
X_test_selected = X_test[selected_feature_names]

"""<center>
    <h3>F. Model Selection and hyper parameter optimization</h3>
    We have decided to Use LinearRegression, DecisionTreeRegression and KNeighborsRegression for our model
</center>
"""

# Define the models
linear_model = LinearRegression()
decision_tree_model = DecisionTreeRegressor()
kneighbors_model = KNeighborsRegressor()

# Define the hyperparameter grids for each model
linear_param_grid = {}

decision_tree_param_grid = {
    'max_depth': [None, 5, 10, 15, 20],
    'min_samples_split': [15, 20, 25, 30, 35],
    'min_samples_leaf': [1, 2, 4, 6, 8, 10]
}

kneighbors_param_grid = {
    'n_neighbors': range(3,11,2),
    'weights': ['uniform', 'distance'],
    'p': [5, 6]
}

# GridSearch for Linear Regression
grid_search_linear = GridSearchCV(linear_model, param_grid=linear_param_grid, scoring='neg_mean_squared_error', cv=5)
grid_search_linear.fit(X_train_selected, y_train) # Training the model with Selected Train DataSet
best_linear_model = grid_search_linear.best_estimator_

# GridSearch for Decision Tree Regressor
grid_search_decision_tree = GridSearchCV(decision_tree_model, param_grid=decision_tree_param_grid, scoring='neg_mean_squared_error', cv=5)
grid_search_decision_tree.fit(X_train_selected, y_train) # Training the model with Selected Train DataSet
best_decision_tree_model = grid_search_decision_tree.best_estimator_

# GridSearch for KNeighbors Regressor
grid_search_kneighbors = GridSearchCV(kneighbors_model, param_grid=kneighbors_param_grid, scoring='neg_mean_squared_error', cv=5)
grid_search_kneighbors.fit(X_train_selected, y_train) # Training the model with Selected Train DataSet
best_kneighbors_model = grid_search_kneighbors.best_estimator_

# Evaluating the Models
def evaluate_model(model, X_test_selected, y_test):
    y_pred = model.predict(X_test_selected)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    return {'R-squared': r2, 'Mean Squared Error': mse, 'Root Mean Squared Error': rmse}

results = {
    "Linear Regression": evaluate_model(best_linear_model, X_test_selected, y_test),
    "Decision Tree Regressor": evaluate_model(best_decision_tree_model, X_test_selected, y_test),
    "KNeighbors Regressor": evaluate_model(best_kneighbors_model, X_test_selected, y_test)
}

print("Model Evaluation Results: \n\n")

for model_name, metrics in results.items():
    print(f"Model: {model_name}")
    for metric_name, value in metrics.items():
        print(f"{metric_name}: {value}")
    print("------------------------")

# Finding the Best performing model
best_model_name = max(results, key=lambda k: results[k]['R-squared'])
best_model = {
    "Model": best_model_name,
    "Metrics": results[best_model_name]
}

# Best Performing Model
print(f"Best Performing Model: {best_model_name}")

"""<center>
    <h3>G. Final Model Training</h3>
</center>
"""

# Combine the training input features and training target feature
train_data = pd.concat([X_train, y_train], axis=1)

# Best performing model
final_model = best_decision_tree_model

# Train the final model on the entire training dataset
final_model.fit(X_train, y_train)

"""<center>
    <h3>H. Result Visualization</h3>
</center>
"""

# Comparing the performance of the Final Model by evaluating it with the Test data
y_predict = final_model.predict(X_test)
train_r2 = r2_score(y_test, y_predict)
train_rmse = np.sqrt(mean_squared_error(y_test, y_predict))

# Print the evaluation results on the training dataset
print("Final Model Evaluation on Training Data:")
print(f"R-squared: {train_r2}")
print(f"Root Mean Squared Error: {train_rmse}")

# Comparing the differences
comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_predict})

fig = px.scatter(comparison_df, x='Actual', y='Predicted', color='Actual')
fig.update_layout(
    title='Comparison of Actual vs. Predicted',
    xaxis_title='Actual',
    yaxis_title='Predicted'
)
fig.show()

# Distribution of Real and Predicted Values
plt.figure(figsize=(8, 6), dpi=300)
sns.histplot(y_test, kde=True, label='Real Values', color='#185ADB')
sns.histplot(y_predict, kde=True, label='Predicted Values', color='#FC5C9C')
plt.xlabel('Life Expectancy')
plt.ylabel('Frequency')
plt.title('Distribution of Real and Predicted Values')
plt.legend()
plt.show()

# Actual vs. Predicted Values Plot
plt.figure(figsize=(8, 6), dpi=300)
plt.scatter(range(len(y_test)), y_test, color='#185ADB', label='Actual Values')
plt.scatter(range(len(y_predict)), y_predict, color='#FC5C9C', label='Predicted Values')
plt.xlabel('Index')
plt.ylabel('Life Expectancy')
plt.title('Actual Values vs. Predicted Values')
plt.legend()
plt.show()

# Residual Plot
residuals = y_test - y_predict
plt.figure(figsize=(8, 6), dpi=300)
plt.scatter(y_predict, residuals, color='#2B3467')
plt.axhline(y=0, color='orange', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()

# Predicted vs. True Line Plot
plt.figure(figsize=(8, 6), dpi=300)
plt.plot(y_test, y_test, color='#98DFD6', label='Ideal Line')
plt.scatter(y_predict, y_predict, color='#00235B', label='Predicted Values')
plt.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, y_predict, 1))(np.unique(y_test)), color='#FFDD83', label='Regression Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs. True Line Plot')
plt.legend()
plt.show()

# Feature Importance Visualization
# feature_importance = final_model.coef_
feature_importance = final_model.feature_importances_
feature_names = X.columns
sorted_idx = np.argsort(abs(feature_importance))

fig = go.Figure()

fig.add_trace(go.Bar(
    x=feature_importance[sorted_idx],
    y=[feature_names[i] for i in sorted_idx],
    orientation='h',
    marker=dict(color='rgba(50, 171, 96, 0.6)'),
    text=feature_importance[sorted_idx],
    textposition='outside'
))

fig.update_layout(
    title='Feature Importance for Final Model',
    xaxis_title='Coefficient Value',
    yaxis_title='Feature',
    yaxis=dict(autorange='reversed'),
    height=500,
)

fig.show()

"""<h4>Conclusion:</h4>

From the Final Feature Importance of Final Model we can see that the selected feature Still Hold Importance and are still relevant in predicting the Performance of the Model.

<ul>
    <li>Status</li>
    <li>Diphtheria</li>
    <li>HIV/AIDS</li>
    <li>BMI</li>
    <li>Schooling</li>
</ul>


The Model has a overall efficiency of 93% which is considered moderate. This level of accuracy suggests that the model has the potential to be a valuable tool for making predictions in the domain under consideration.

Further improvements and optimizations may be explored to enhance the model's performance, but the selected features remain critical elements contributing to its predictive capability.
"""

